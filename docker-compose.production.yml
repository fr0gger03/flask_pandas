# Production Docker Compose for Flask Workload Parser with Gunicorn
# Simplified production setup with PostgreSQL and Gunicorn only
# References:
# - https://docs.docker.com/compose/production/
# - https://flask.palletsprojects.com/en/stable/deploying/gunicorn/

services:
  # PostgreSQL Database
  db:
    image: postgres:17.4
    ports:
      - "5432:5432"
    volumes:
      - ./parser/sql:/docker-entrypoint-initdb.d
      - postgres_data_prod:/var/lib/postgresql/data
    networks:
      - app_network_prod
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    restart: always
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "inventorydbuser", "-d", "inventorydb"]
      interval: 10s
      timeout: 5s
      retries: 5


  # db:
  #   image: postgres:15-alpine
  #   container_name: workload_parser_db_prod
  #   environment:
  #     POSTGRES_DB: inventorydb
  #     POSTGRES_USER: postgres
  #     POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
  #   volumes:
  #     - ./parser/sql:/docker-entrypoint-initdb.d
  #     - postgres_data_prod:/var/lib/postgresql/data
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "pg_isready", "-U", "inventorydbuser", "-d", "inventorydb"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5

  # Flask Application with Gunicorn
  app:
    build:
      context: .
      dockerfile: Dockerfile.production
    container_name: workload_parser_app_prod
    ports:
      - "8000:8000"  # Expose Gunicorn directly
    environment:
      # Flask configuration
      - FLASK_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - SECRET_KEY=${SECRET_KEY}
      - UPLOAD_FOLDER=${UPLOAD_FOLDER}
      # Security settings
      - WTF_CSRF_ENABLED=true
      - WTF_CSRF_TIME_LIMIT=3600
      # File upload limits - 10GB for large datasets
      - MAX_CONTENT_LENGTH=10737418240  # 10GB
    volumes:
      # Persistent storage for uploaded files and logs
      - app_input_prod:/app/parser/input
      - app_logs_prod:/app/logs
    networks:
      - app_network_prod
    depends_on:
      db:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Resource limits for production stability
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # Adminer for Database Management (Optional)
  adminer:
    image: adminer:latest
    container_name: workload_parser_adminer_prod
    ports:
      - "8081:8080"
    networks:
      - app_network_prod
    restart: unless-stopped
    profiles:
      - debug  # Only start with --profile debug
    environment:
      ADMINER_DEFAULT_SERVER: db

volumes:
  # Persistent data volumes
  postgres_data_prod:
    driver: local
  app_input_prod:
    driver: local
  app_logs_prod:
    driver: local

networks:
  app_network_prod:
    driver: bridge

# Production deployment instructions:
#
# 1. Create environment file (.env.production):
#    POSTGRES_PASSWORD=your-secure-database-password
#    DATABASE_URL=postgresql://inventorydbuser:your-secure-database-password@db:5432/inventorydb
#    SECRET_KEY=your-super-secret-key-change-this-in-production
#
# 2. Deploy:
#    docker compose -f docker-compose.production.yml --env-file .env.production up -d
#
# 3. Check service health:
#    docker compose -f docker-compose.production.yml ps
#    docker compose -f docker-compose.production.yml logs app
#
# 4. Access application:
#    http://localhost:8000
#
# 5. Include adminer for database management:
#    docker compose -f docker-compose.production.yml --profile debug up -d
#    Access at: http://localhost:8081
#
# 6. Scale app instances (if needed):
#    docker compose -f docker-compose.production.yml up -d --scale app=2
#
# 7. View application logs:
#    docker compose -f docker-compose.production.yml logs -f app
#
# 8. Stop services:
#    docker compose -f docker-compose.production.yml down
#
# 9. Stop and remove volumes (careful - this deletes data):
#    docker compose -f docker-compose.production.yml down -v
#
# Health checks:
# - Application: curl http://localhost:8000/health
# - Database: docker compose -f docker-compose.production.yml exec db pg_isready -U postgres
#
# Gunicorn features enabled:
# - Multi-worker processes for concurrency
# - Extended timeouts for file processing (300s)
# - Automatic worker recycling (1000 requests)
# - Health monitoring via /health endpoint
# - Production logging to stdout/stderr
#
# Security notes:
# - Database is not exposed externally (no ports mapping for db service)
# - Uses environment variables for sensitive data
# - Non-root user in container
# - Resource limits prevent resource exhaustion
