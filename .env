# Production Environment Configuration for Flask Workload Parser
# Copy this file to .env.production and update with your actual values

# Flask Configuration
FLASK_ENV=production
FLASK_DEBUG=False
SECRET_KEY=your-super-secret-key-change-this-in-production-use-random-64-chars

# Database Configuration
# Use PostgreSQL for production
POSTGRES_PASSWORD=password
DATABASE_URL=postgresql://inventorydbuser:password@db:5432/inventorydb

# Security Settings
WTF_CSRF_ENABLED=True
WTF_CSRF_TIME_LIMIT=3600

# File Upload Configuration - 10GB Support
UPLOAD_FOLDER=parser/input/
MAX_CONTENT_LENGTH=10737418240  # 10GB in bytes (10 * 1024 * 1024 * 1024)

# Alternative file size limits (uncomment to use different limits):
# MAX_CONTENT_LENGTH=1073741824    # 1GB
# MAX_CONTENT_LENGTH=5368709120    # 5GB
# MAX_CONTENT_LENGTH=21474836480   # 20GB

# Redis Configuration (optional - for session storage and caching)
# Uncomment if using Redis:
# REDIS_URL=redis://redis:6379/0
# SESSION_TYPE=redis
# SESSION_REDIS_URL=redis://redis:6379/0
# SESSION_PERMANENT=False
# SESSION_USE_SIGNER=True
# SESSION_KEY_PREFIX=workload_parser:

# Sentry Configuration (optional - for error monitoring)
# Get your DSN from https://sentry.io
# SENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s %(levelname)s %(name)s %(message)s

# Server Configuration (if using in production with domain)
# SERVER_NAME=your-domain.com
# PREFERRED_URL_SCHEME=https

# Performance Tuning
# Gunicorn workers (calculated automatically, but can override)
# GUNICORN_WORKERS=4

# Application-specific settings
# Max rows to process in memory at once (for very large files)
PANDAS_CHUNK_SIZE=10000

# Database connection pool settings (optional)
# SQLALCHEMY_ENGINE_OPTIONS={"pool_pre_ping": True, "pool_recycle": 300}

# File processing settings
# Maximum processing time for uploads (seconds)
UPLOAD_TIMEOUT=3600  # 1 hour

# Cleanup settings
# Delete uploaded files after processing (True/False)
CLEANUP_UPLOADS=True

# Memory management
# Maximum memory usage for pandas operations (MB)
PANDAS_MAX_MEMORY=2048  # 2GB

# Additional environment variables for container deployment
PYTHONUNBUFFERED=1
PYTHONDONTWRITEBYTECODE=1
